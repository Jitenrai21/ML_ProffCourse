{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2jCuvPejg71q"
      },
      "outputs": [],
      "source": [
        "docs = \"\"\"\n",
        "Exploring the Wonders of Space\n",
        "What are black holes, and why are they significant?\n",
        "Black holes are regions in space where gravity is so strong that nothing, not even light, can escape.\n",
        "They are significant because they help scientists understand the limits of physics, particularly how gravity interacts with spacetime.\n",
        "How do stars influence the universe?\n",
        "Stars are the building blocks of galaxies.\n",
        "They produce light and heat through nuclear fusion, creating elements essential for life.\n",
        "Stars also play a role in forming planets and distributing energy throughout the universe.\n",
        "What is the importance of space exploration?\n",
        "Space exploration expands our knowledge of the universe and helps develop new technologies.\n",
        "It inspires innovation, provides a better understanding of Earth’s place in the cosmos, and may someday enable humanity to inhabit other planets.\n",
        "How are scientists searching for life beyond Earth?\n",
        "Scientists use telescopes to analyze exoplanets' atmospheres and look for conditions that could support life.\n",
        "Missions like the James Webb Space Telescope and Mars rovers aim to uncover signs of water, organic molecules, or microbial life.\n",
        "What role do humans have in shaping the future of space?\n",
        "Human efforts in space exploration, like building space stations and planning missions to Mars, will pave the way for interplanetary travel.\n",
        "Innovations inspired by space research may lead to sustainable solutions on Earth and beyond.\n",
        "Can ordinary people contribute to space science?\n",
        "Yes, through initiatives like citizen science projects, people can help analyze astronomical data, identify celestial phenomena, and support space missions. These collaborations make space exploration more inclusive and impactful.\n",
        "Where can we learn more about the universe?\n",
        "Many organizations, like NASA, ESA, and local astronomy clubs, provide free resources and events.\n",
        "Online platforms like YouTube and educational websites are also excellent places to deepen your knowledge.\n",
        "Hello k xa khaber.\n",
        "K gardai xaau timi.\n",
        "kasto bhai ra xa pada.\n",
        "Khana khanu bha ko.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "N4GsYzSOhTYA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "khkg8J7XhWuC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "oWR1lxdzhksd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([docs])"
      ],
      "metadata": {
        "id": "NAngKej0hr3l"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5RnM_Hch1fH",
        "outputId": "d45cb970-b407-4080-e3fa-4dd5e536baa8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'the': 2,\n",
              " 'space': 3,\n",
              " 'of': 4,\n",
              " 'are': 5,\n",
              " 'to': 6,\n",
              " 'in': 7,\n",
              " 'like': 8,\n",
              " 'they': 9,\n",
              " 'can': 10,\n",
              " 'universe': 11,\n",
              " 'for': 12,\n",
              " 'life': 13,\n",
              " 'exploration': 14,\n",
              " 'what': 15,\n",
              " 'scientists': 16,\n",
              " 'how': 17,\n",
              " 'stars': 18,\n",
              " 'missions': 19,\n",
              " 'black': 20,\n",
              " 'holes': 21,\n",
              " 'significant': 22,\n",
              " 'where': 23,\n",
              " 'gravity': 24,\n",
              " 'is': 25,\n",
              " 'that': 26,\n",
              " 'light': 27,\n",
              " 'help': 28,\n",
              " 'do': 29,\n",
              " 'building': 30,\n",
              " 'through': 31,\n",
              " 'also': 32,\n",
              " 'a': 33,\n",
              " 'role': 34,\n",
              " 'planets': 35,\n",
              " 'knowledge': 36,\n",
              " 'may': 37,\n",
              " 'beyond': 38,\n",
              " 'earth': 39,\n",
              " 'analyze': 40,\n",
              " 'support': 41,\n",
              " 'mars': 42,\n",
              " 'people': 43,\n",
              " 'science': 44,\n",
              " 'more': 45,\n",
              " 'k': 46,\n",
              " 'xa': 47,\n",
              " 'exploring': 48,\n",
              " 'wonders': 49,\n",
              " 'why': 50,\n",
              " 'regions': 51,\n",
              " 'so': 52,\n",
              " 'strong': 53,\n",
              " 'nothing': 54,\n",
              " 'not': 55,\n",
              " 'even': 56,\n",
              " 'escape': 57,\n",
              " 'because': 58,\n",
              " 'understand': 59,\n",
              " 'limits': 60,\n",
              " 'physics': 61,\n",
              " 'particularly': 62,\n",
              " 'interacts': 63,\n",
              " 'with': 64,\n",
              " 'spacetime': 65,\n",
              " 'influence': 66,\n",
              " 'blocks': 67,\n",
              " 'galaxies': 68,\n",
              " 'produce': 69,\n",
              " 'heat': 70,\n",
              " 'nuclear': 71,\n",
              " 'fusion': 72,\n",
              " 'creating': 73,\n",
              " 'elements': 74,\n",
              " 'essential': 75,\n",
              " 'play': 76,\n",
              " 'forming': 77,\n",
              " 'distributing': 78,\n",
              " 'energy': 79,\n",
              " 'throughout': 80,\n",
              " 'importance': 81,\n",
              " 'expands': 82,\n",
              " 'our': 83,\n",
              " 'helps': 84,\n",
              " 'develop': 85,\n",
              " 'new': 86,\n",
              " 'technologies': 87,\n",
              " 'it': 88,\n",
              " 'inspires': 89,\n",
              " 'innovation': 90,\n",
              " 'provides': 91,\n",
              " 'better': 92,\n",
              " 'understanding': 93,\n",
              " 'earth’s': 94,\n",
              " 'place': 95,\n",
              " 'cosmos': 96,\n",
              " 'someday': 97,\n",
              " 'enable': 98,\n",
              " 'humanity': 99,\n",
              " 'inhabit': 100,\n",
              " 'other': 101,\n",
              " 'searching': 102,\n",
              " 'use': 103,\n",
              " 'telescopes': 104,\n",
              " \"exoplanets'\": 105,\n",
              " 'atmospheres': 106,\n",
              " 'look': 107,\n",
              " 'conditions': 108,\n",
              " 'could': 109,\n",
              " 'james': 110,\n",
              " 'webb': 111,\n",
              " 'telescope': 112,\n",
              " 'rovers': 113,\n",
              " 'aim': 114,\n",
              " 'uncover': 115,\n",
              " 'signs': 116,\n",
              " 'water': 117,\n",
              " 'organic': 118,\n",
              " 'molecules': 119,\n",
              " 'or': 120,\n",
              " 'microbial': 121,\n",
              " 'humans': 122,\n",
              " 'have': 123,\n",
              " 'shaping': 124,\n",
              " 'future': 125,\n",
              " 'human': 126,\n",
              " 'efforts': 127,\n",
              " 'stations': 128,\n",
              " 'planning': 129,\n",
              " 'will': 130,\n",
              " 'pave': 131,\n",
              " 'way': 132,\n",
              " 'interplanetary': 133,\n",
              " 'travel': 134,\n",
              " 'innovations': 135,\n",
              " 'inspired': 136,\n",
              " 'by': 137,\n",
              " 'research': 138,\n",
              " 'lead': 139,\n",
              " 'sustainable': 140,\n",
              " 'solutions': 141,\n",
              " 'on': 142,\n",
              " 'ordinary': 143,\n",
              " 'contribute': 144,\n",
              " 'yes': 145,\n",
              " 'initiatives': 146,\n",
              " 'citizen': 147,\n",
              " 'projects': 148,\n",
              " 'astronomical': 149,\n",
              " 'data': 150,\n",
              " 'identify': 151,\n",
              " 'celestial': 152,\n",
              " 'phenomena': 153,\n",
              " 'these': 154,\n",
              " 'collaborations': 155,\n",
              " 'make': 156,\n",
              " 'inclusive': 157,\n",
              " 'impactful': 158,\n",
              " 'we': 159,\n",
              " 'learn': 160,\n",
              " 'about': 161,\n",
              " 'many': 162,\n",
              " 'organizations': 163,\n",
              " 'nasa': 164,\n",
              " 'esa': 165,\n",
              " 'local': 166,\n",
              " 'astronomy': 167,\n",
              " 'clubs': 168,\n",
              " 'provide': 169,\n",
              " 'free': 170,\n",
              " 'resources': 171,\n",
              " 'events': 172,\n",
              " 'online': 173,\n",
              " 'platforms': 174,\n",
              " 'youtube': 175,\n",
              " 'educational': 176,\n",
              " 'websites': 177,\n",
              " 'excellent': 178,\n",
              " 'places': 179,\n",
              " 'deepen': 180,\n",
              " 'your': 181,\n",
              " 'hello': 182,\n",
              " 'khaber': 183,\n",
              " 'gardai': 184,\n",
              " 'xaau': 185,\n",
              " 'timi': 186,\n",
              " 'kasto': 187,\n",
              " 'bhai': 188,\n",
              " 'ra': 189,\n",
              " 'pada': 190,\n",
              " 'khana': 191,\n",
              " 'khanu': 192,\n",
              " 'bha': 193,\n",
              " 'ko': 194}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA2a-yNziB3a",
        "outputId": "0430c495-8c3d-49d7-985d-196a454c522b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "for sentence in docs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_sequence.append(tokenized_sentence[:i + 1])\n",
        "\n",
        "input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kceA6N1li2Rs",
        "outputId": "8d9d2043-2dfd-4a7f-f5b9-51f90c6fbf07"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[48, 2],\n",
              " [48, 2, 49],\n",
              " [48, 2, 49, 4],\n",
              " [48, 2, 49, 4, 3],\n",
              " [15, 5],\n",
              " [15, 5, 20],\n",
              " [15, 5, 20, 21],\n",
              " [15, 5, 20, 21, 1],\n",
              " [15, 5, 20, 21, 1, 50],\n",
              " [15, 5, 20, 21, 1, 50, 5],\n",
              " [15, 5, 20, 21, 1, 50, 5, 9],\n",
              " [15, 5, 20, 21, 1, 50, 5, 9, 22],\n",
              " [20, 21],\n",
              " [20, 21, 5],\n",
              " [20, 21, 5, 51],\n",
              " [20, 21, 5, 51, 7],\n",
              " [20, 21, 5, 51, 7, 3],\n",
              " [20, 21, 5, 51, 7, 3, 23],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53, 26],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53, 26, 54],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53, 26, 54, 55],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53, 26, 54, 55, 56],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53, 26, 54, 55, 56, 27],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53, 26, 54, 55, 56, 27, 10],\n",
              " [20, 21, 5, 51, 7, 3, 23, 24, 25, 52, 53, 26, 54, 55, 56, 27, 10, 57],\n",
              " [9, 5],\n",
              " [9, 5, 22],\n",
              " [9, 5, 22, 58],\n",
              " [9, 5, 22, 58, 9],\n",
              " [9, 5, 22, 58, 9, 28],\n",
              " [9, 5, 22, 58, 9, 28, 16],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4, 61],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4, 61, 62],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4, 61, 62, 17],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4, 61, 62, 17, 24],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4, 61, 62, 17, 24, 63],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4, 61, 62, 17, 24, 63, 64],\n",
              " [9, 5, 22, 58, 9, 28, 16, 59, 2, 60, 4, 61, 62, 17, 24, 63, 64, 65],\n",
              " [17, 29],\n",
              " [17, 29, 18],\n",
              " [17, 29, 18, 66],\n",
              " [17, 29, 18, 66, 2],\n",
              " [17, 29, 18, 66, 2, 11],\n",
              " [18, 5],\n",
              " [18, 5, 2],\n",
              " [18, 5, 2, 30],\n",
              " [18, 5, 2, 30, 67],\n",
              " [18, 5, 2, 30, 67, 4],\n",
              " [18, 5, 2, 30, 67, 4, 68],\n",
              " [9, 69],\n",
              " [9, 69, 27],\n",
              " [9, 69, 27, 1],\n",
              " [9, 69, 27, 1, 70],\n",
              " [9, 69, 27, 1, 70, 31],\n",
              " [9, 69, 27, 1, 70, 31, 71],\n",
              " [9, 69, 27, 1, 70, 31, 71, 72],\n",
              " [9, 69, 27, 1, 70, 31, 71, 72, 73],\n",
              " [9, 69, 27, 1, 70, 31, 71, 72, 73, 74],\n",
              " [9, 69, 27, 1, 70, 31, 71, 72, 73, 74, 75],\n",
              " [9, 69, 27, 1, 70, 31, 71, 72, 73, 74, 75, 12],\n",
              " [9, 69, 27, 1, 70, 31, 71, 72, 73, 74, 75, 12, 13],\n",
              " [18, 32],\n",
              " [18, 32, 76],\n",
              " [18, 32, 76, 33],\n",
              " [18, 32, 76, 33, 34],\n",
              " [18, 32, 76, 33, 34, 7],\n",
              " [18, 32, 76, 33, 34, 7, 77],\n",
              " [18, 32, 76, 33, 34, 7, 77, 35],\n",
              " [18, 32, 76, 33, 34, 7, 77, 35, 1],\n",
              " [18, 32, 76, 33, 34, 7, 77, 35, 1, 78],\n",
              " [18, 32, 76, 33, 34, 7, 77, 35, 1, 78, 79],\n",
              " [18, 32, 76, 33, 34, 7, 77, 35, 1, 78, 79, 80],\n",
              " [18, 32, 76, 33, 34, 7, 77, 35, 1, 78, 79, 80, 2],\n",
              " [18, 32, 76, 33, 34, 7, 77, 35, 1, 78, 79, 80, 2, 11],\n",
              " [15, 25],\n",
              " [15, 25, 2],\n",
              " [15, 25, 2, 81],\n",
              " [15, 25, 2, 81, 4],\n",
              " [15, 25, 2, 81, 4, 3],\n",
              " [15, 25, 2, 81, 4, 3, 14],\n",
              " [3, 14],\n",
              " [3, 14, 82],\n",
              " [3, 14, 82, 83],\n",
              " [3, 14, 82, 83, 36],\n",
              " [3, 14, 82, 83, 36, 4],\n",
              " [3, 14, 82, 83, 36, 4, 2],\n",
              " [3, 14, 82, 83, 36, 4, 2, 11],\n",
              " [3, 14, 82, 83, 36, 4, 2, 11, 1],\n",
              " [3, 14, 82, 83, 36, 4, 2, 11, 1, 84],\n",
              " [3, 14, 82, 83, 36, 4, 2, 11, 1, 84, 85],\n",
              " [3, 14, 82, 83, 36, 4, 2, 11, 1, 84, 85, 86],\n",
              " [3, 14, 82, 83, 36, 4, 2, 11, 1, 84, 85, 86, 87],\n",
              " [88, 89],\n",
              " [88, 89, 90],\n",
              " [88, 89, 90, 91],\n",
              " [88, 89, 90, 91, 33],\n",
              " [88, 89, 90, 91, 33, 92],\n",
              " [88, 89, 90, 91, 33, 92, 93],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96, 1],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96, 1, 37],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96, 1, 37, 97],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96, 1, 37, 97, 98],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96, 1, 37, 97, 98, 99],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96, 1, 37, 97, 98, 99, 6],\n",
              " [88, 89, 90, 91, 33, 92, 93, 4, 94, 95, 7, 2, 96, 1, 37, 97, 98, 99, 6, 100],\n",
              " [88,\n",
              "  89,\n",
              "  90,\n",
              "  91,\n",
              "  33,\n",
              "  92,\n",
              "  93,\n",
              "  4,\n",
              "  94,\n",
              "  95,\n",
              "  7,\n",
              "  2,\n",
              "  96,\n",
              "  1,\n",
              "  37,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  6,\n",
              "  100,\n",
              "  101],\n",
              " [88,\n",
              "  89,\n",
              "  90,\n",
              "  91,\n",
              "  33,\n",
              "  92,\n",
              "  93,\n",
              "  4,\n",
              "  94,\n",
              "  95,\n",
              "  7,\n",
              "  2,\n",
              "  96,\n",
              "  1,\n",
              "  37,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  6,\n",
              "  100,\n",
              "  101,\n",
              "  35],\n",
              " [17, 5],\n",
              " [17, 5, 16],\n",
              " [17, 5, 16, 102],\n",
              " [17, 5, 16, 102, 12],\n",
              " [17, 5, 16, 102, 12, 13],\n",
              " [17, 5, 16, 102, 12, 13, 38],\n",
              " [17, 5, 16, 102, 12, 13, 38, 39],\n",
              " [16, 103],\n",
              " [16, 103, 104],\n",
              " [16, 103, 104, 6],\n",
              " [16, 103, 104, 6, 40],\n",
              " [16, 103, 104, 6, 40, 105],\n",
              " [16, 103, 104, 6, 40, 105, 106],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1, 107],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1, 107, 12],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1, 107, 12, 108],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1, 107, 12, 108, 26],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1, 107, 12, 108, 26, 109],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1, 107, 12, 108, 26, 109, 41],\n",
              " [16, 103, 104, 6, 40, 105, 106, 1, 107, 12, 108, 26, 109, 41, 13],\n",
              " [19, 8],\n",
              " [19, 8, 2],\n",
              " [19, 8, 2, 110],\n",
              " [19, 8, 2, 110, 111],\n",
              " [19, 8, 2, 110, 111, 3],\n",
              " [19, 8, 2, 110, 111, 3, 112],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114, 6],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114, 6, 115],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114, 6, 115, 116],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114, 6, 115, 116, 4],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114, 6, 115, 116, 4, 117],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114, 6, 115, 116, 4, 117, 118],\n",
              " [19, 8, 2, 110, 111, 3, 112, 1, 42, 113, 114, 6, 115, 116, 4, 117, 118, 119],\n",
              " [19,\n",
              "  8,\n",
              "  2,\n",
              "  110,\n",
              "  111,\n",
              "  3,\n",
              "  112,\n",
              "  1,\n",
              "  42,\n",
              "  113,\n",
              "  114,\n",
              "  6,\n",
              "  115,\n",
              "  116,\n",
              "  4,\n",
              "  117,\n",
              "  118,\n",
              "  119,\n",
              "  120],\n",
              " [19,\n",
              "  8,\n",
              "  2,\n",
              "  110,\n",
              "  111,\n",
              "  3,\n",
              "  112,\n",
              "  1,\n",
              "  42,\n",
              "  113,\n",
              "  114,\n",
              "  6,\n",
              "  115,\n",
              "  116,\n",
              "  4,\n",
              "  117,\n",
              "  118,\n",
              "  119,\n",
              "  120,\n",
              "  121],\n",
              " [19,\n",
              "  8,\n",
              "  2,\n",
              "  110,\n",
              "  111,\n",
              "  3,\n",
              "  112,\n",
              "  1,\n",
              "  42,\n",
              "  113,\n",
              "  114,\n",
              "  6,\n",
              "  115,\n",
              "  116,\n",
              "  4,\n",
              "  117,\n",
              "  118,\n",
              "  119,\n",
              "  120,\n",
              "  121,\n",
              "  13],\n",
              " [15, 34],\n",
              " [15, 34, 29],\n",
              " [15, 34, 29, 122],\n",
              " [15, 34, 29, 122, 123],\n",
              " [15, 34, 29, 122, 123, 7],\n",
              " [15, 34, 29, 122, 123, 7, 124],\n",
              " [15, 34, 29, 122, 123, 7, 124, 2],\n",
              " [15, 34, 29, 122, 123, 7, 124, 2, 125],\n",
              " [15, 34, 29, 122, 123, 7, 124, 2, 125, 4],\n",
              " [15, 34, 29, 122, 123, 7, 124, 2, 125, 4, 3],\n",
              " [126, 127],\n",
              " [126, 127, 7],\n",
              " [126, 127, 7, 3],\n",
              " [126, 127, 7, 3, 14],\n",
              " [126, 127, 7, 3, 14, 8],\n",
              " [126, 127, 7, 3, 14, 8, 30],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19, 6],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19, 6, 42],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19, 6, 42, 130],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19, 6, 42, 130, 131],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19, 6, 42, 130, 131, 2],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19, 6, 42, 130, 131, 2, 132],\n",
              " [126, 127, 7, 3, 14, 8, 30, 3, 128, 1, 129, 19, 6, 42, 130, 131, 2, 132, 12],\n",
              " [126,\n",
              "  127,\n",
              "  7,\n",
              "  3,\n",
              "  14,\n",
              "  8,\n",
              "  30,\n",
              "  3,\n",
              "  128,\n",
              "  1,\n",
              "  129,\n",
              "  19,\n",
              "  6,\n",
              "  42,\n",
              "  130,\n",
              "  131,\n",
              "  2,\n",
              "  132,\n",
              "  12,\n",
              "  133],\n",
              " [126,\n",
              "  127,\n",
              "  7,\n",
              "  3,\n",
              "  14,\n",
              "  8,\n",
              "  30,\n",
              "  3,\n",
              "  128,\n",
              "  1,\n",
              "  129,\n",
              "  19,\n",
              "  6,\n",
              "  42,\n",
              "  130,\n",
              "  131,\n",
              "  2,\n",
              "  132,\n",
              "  12,\n",
              "  133,\n",
              "  134],\n",
              " [135, 136],\n",
              " [135, 136, 137],\n",
              " [135, 136, 137, 3],\n",
              " [135, 136, 137, 3, 138],\n",
              " [135, 136, 137, 3, 138, 37],\n",
              " [135, 136, 137, 3, 138, 37, 139],\n",
              " [135, 136, 137, 3, 138, 37, 139, 6],\n",
              " [135, 136, 137, 3, 138, 37, 139, 6, 140],\n",
              " [135, 136, 137, 3, 138, 37, 139, 6, 140, 141],\n",
              " [135, 136, 137, 3, 138, 37, 139, 6, 140, 141, 142],\n",
              " [135, 136, 137, 3, 138, 37, 139, 6, 140, 141, 142, 39],\n",
              " [135, 136, 137, 3, 138, 37, 139, 6, 140, 141, 142, 39, 1],\n",
              " [135, 136, 137, 3, 138, 37, 139, 6, 140, 141, 142, 39, 1, 38],\n",
              " [10, 143],\n",
              " [10, 143, 43],\n",
              " [10, 143, 43, 144],\n",
              " [10, 143, 43, 144, 6],\n",
              " [10, 143, 43, 144, 6, 3],\n",
              " [10, 143, 43, 144, 6, 3, 44],\n",
              " [145, 31],\n",
              " [145, 31, 146],\n",
              " [145, 31, 146, 8],\n",
              " [145, 31, 146, 8, 147],\n",
              " [145, 31, 146, 8, 147, 44],\n",
              " [145, 31, 146, 8, 147, 44, 148],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28, 40],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28, 40, 149],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28, 40, 149, 150],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28, 40, 149, 150, 151],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28, 40, 149, 150, 151, 152],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28, 40, 149, 150, 151, 152, 153],\n",
              " [145, 31, 146, 8, 147, 44, 148, 43, 10, 28, 40, 149, 150, 151, 152, 153, 1],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155,\n",
              "  156],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155,\n",
              "  156,\n",
              "  3],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155,\n",
              "  156,\n",
              "  3,\n",
              "  14],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155,\n",
              "  156,\n",
              "  3,\n",
              "  14,\n",
              "  45],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155,\n",
              "  156,\n",
              "  3,\n",
              "  14,\n",
              "  45,\n",
              "  157],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155,\n",
              "  156,\n",
              "  3,\n",
              "  14,\n",
              "  45,\n",
              "  157,\n",
              "  1],\n",
              " [145,\n",
              "  31,\n",
              "  146,\n",
              "  8,\n",
              "  147,\n",
              "  44,\n",
              "  148,\n",
              "  43,\n",
              "  10,\n",
              "  28,\n",
              "  40,\n",
              "  149,\n",
              "  150,\n",
              "  151,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  41,\n",
              "  3,\n",
              "  19,\n",
              "  154,\n",
              "  155,\n",
              "  156,\n",
              "  3,\n",
              "  14,\n",
              "  45,\n",
              "  157,\n",
              "  1,\n",
              "  158],\n",
              " [23, 10],\n",
              " [23, 10, 159],\n",
              " [23, 10, 159, 160],\n",
              " [23, 10, 159, 160, 45],\n",
              " [23, 10, 159, 160, 45, 161],\n",
              " [23, 10, 159, 160, 45, 161, 2],\n",
              " [23, 10, 159, 160, 45, 161, 2, 11],\n",
              " [162, 163],\n",
              " [162, 163, 8],\n",
              " [162, 163, 8, 164],\n",
              " [162, 163, 8, 164, 165],\n",
              " [162, 163, 8, 164, 165, 1],\n",
              " [162, 163, 8, 164, 165, 1, 166],\n",
              " [162, 163, 8, 164, 165, 1, 166, 167],\n",
              " [162, 163, 8, 164, 165, 1, 166, 167, 168],\n",
              " [162, 163, 8, 164, 165, 1, 166, 167, 168, 169],\n",
              " [162, 163, 8, 164, 165, 1, 166, 167, 168, 169, 170],\n",
              " [162, 163, 8, 164, 165, 1, 166, 167, 168, 169, 170, 171],\n",
              " [162, 163, 8, 164, 165, 1, 166, 167, 168, 169, 170, 171, 1],\n",
              " [162, 163, 8, 164, 165, 1, 166, 167, 168, 169, 170, 171, 1, 172],\n",
              " [173, 174],\n",
              " [173, 174, 8],\n",
              " [173, 174, 8, 175],\n",
              " [173, 174, 8, 175, 1],\n",
              " [173, 174, 8, 175, 1, 176],\n",
              " [173, 174, 8, 175, 1, 176, 177],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5, 32],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5, 32, 178],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5, 32, 178, 179],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5, 32, 178, 179, 6],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5, 32, 178, 179, 6, 180],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5, 32, 178, 179, 6, 180, 181],\n",
              " [173, 174, 8, 175, 1, 176, 177, 5, 32, 178, 179, 6, 180, 181, 36],\n",
              " [182, 46],\n",
              " [182, 46, 47],\n",
              " [182, 46, 47, 183],\n",
              " [46, 184],\n",
              " [46, 184, 185],\n",
              " [46, 184, 185, 186],\n",
              " [187, 188],\n",
              " [187, 188, 189],\n",
              " [187, 188, 189, 47],\n",
              " [187, 188, 189, 47, 190],\n",
              " [191, 192],\n",
              " [191, 192, 193],\n",
              " [191, 192, 193, 194]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequence])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1pRXr15lUjp",
        "outputId": "db67a2e0-9d9f-4703-ada1-4b59c8f43375"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequence, maxlen= max_len, padding='pre')"
      ],
      "metadata": {
        "id": "Xa6BXGb3mhtl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpu9FVC1nDM7",
        "outputId": "4619baf6-63ba-4756-9b09-14f5ffd4a0e2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  48,   2],\n",
              "       [  0,   0,   0, ...,  48,   2,  49],\n",
              "       [  0,   0,   0, ...,   2,  49,   4],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0, 191, 192],\n",
              "       [  0,   0,   0, ..., 191, 192, 193],\n",
              "       [  0,   0,   0, ..., 192, 193, 194]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "_wXwE5FfnKpB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30l2_p14oG9i",
        "outputId": "549d92f0-5316-4d97-86d7-e5f43be77eaf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXEpDppwofb0",
        "outputId": "3410aa9b-2161-40ec-c768-436bc8417c0a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286,)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes = 195)"
      ],
      "metadata": {
        "id": "5KWeT-MIog68"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7hEGeDaqdKr",
        "outputId": "6ada7635-e2a0-4d42-83c5-8892962233cc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(286, 195)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM"
      ],
      "metadata": {
        "id": "mW6FHDCoqkBw"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(195, 100, input_length=28))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(195, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBVjgmyCrFI2",
        "outputId": "91f9d95a-ad3e-44eb-bf84-237ab16284d3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FhHyUQGRsclb"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()"
      ],
      "metadata": {
        "id": "1GtUhP5QuWz8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pwKSsXcuYfo",
        "outputId": "254fd61a-db52-45cf-8d9d-9b0508e8c439"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - accuracy: 0.0186 - loss: 5.2720\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.0487 - loss: 5.1980\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.0530 - loss: 5.0017\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.0433 - loss: 4.9339\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.0433 - loss: 4.9477\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.0748 - loss: 4.7718\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.0657 - loss: 4.7453\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.0921 - loss: 4.6458\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0944 - loss: 4.5753\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.0482 - loss: 4.5238\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.0615 - loss: 4.4738\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.0764 - loss: 4.3588\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.1005 - loss: 4.1726\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.0817 - loss: 4.2311\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1014 - loss: 4.0968\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1076 - loss: 3.9924\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.0960 - loss: 3.9932\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1209 - loss: 3.8018\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1684 - loss: 3.6863\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1379 - loss: 3.5927\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1854 - loss: 3.5128\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.1887 - loss: 3.3547\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.1959 - loss: 3.2980\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.1827 - loss: 3.2218\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.2750 - loss: 3.0117\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.2985 - loss: 2.9902\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.3216 - loss: 2.7797\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.4250 - loss: 2.5958\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4673 - loss: 2.4974\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5150 - loss: 2.4400\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5134 - loss: 2.3512\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5558 - loss: 2.2164\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5703 - loss: 2.1395\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5926 - loss: 2.0668\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6236 - loss: 1.9265\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7135 - loss: 1.7807\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7403 - loss: 1.7414\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7572 - loss: 1.6659\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7419 - loss: 1.6225\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8081 - loss: 1.4828\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8168 - loss: 1.4619\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8861 - loss: 1.3314\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8496 - loss: 1.3499\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8692 - loss: 1.2273\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.8827 - loss: 1.1576\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8765 - loss: 1.1653\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9193 - loss: 1.0713\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9138 - loss: 1.0367\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9126 - loss: 1.0092\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9231 - loss: 0.9375\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9305 - loss: 0.9056\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9547 - loss: 0.8460\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9618 - loss: 0.8447\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9696 - loss: 0.8139\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9565 - loss: 0.7842\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9776 - loss: 0.6863\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9691 - loss: 0.7089\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9826 - loss: 0.6562\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9859 - loss: 0.6038\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9858 - loss: 0.5879\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9887 - loss: 0.5452\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9840 - loss: 0.5662\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9730 - loss: 0.5361\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9842 - loss: 0.4969\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9841 - loss: 0.4939\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9712 - loss: 0.4661\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9903 - loss: 0.4483\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9841 - loss: 0.4227\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9798 - loss: 0.4092\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9768 - loss: 0.3874\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9902 - loss: 0.3834\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9739 - loss: 0.3820\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9878 - loss: 0.3565\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9710 - loss: 0.3636\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9875 - loss: 0.3170\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9869 - loss: 0.3255\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9870 - loss: 0.3078\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9829 - loss: 0.2933\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9859 - loss: 0.2837\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9915 - loss: 0.2670\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9810 - loss: 0.2802\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9712 - loss: 0.2747\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9886 - loss: 0.2406\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9844 - loss: 0.2548\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9854 - loss: 0.2308\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9824 - loss: 0.2254\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9778 - loss: 0.2243\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9888 - loss: 0.2153\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9882 - loss: 0.2076\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9886 - loss: 0.2056\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9834 - loss: 0.1914\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9828 - loss: 0.1954\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9640 - loss: 0.2037\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9668 - loss: 0.1880\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9880 - loss: 0.1685\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9819 - loss: 0.1782\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9836 - loss: 0.1643\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9671 - loss: 0.1645\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9733 - loss: 0.1644\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9856 - loss: 0.1508\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1f86f2e860>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(r'C:\\Users\\ACER\\gitClones\\ML_ProffCourse\\Day-12\\WordPrediction.h5')"
      ],
      "metadata": {
        "id": "BAR8CKzSuivd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb6f1d2-4084-4fff-e628-47f4bee6f4f5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "_c1MK6bIwgdZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(r'C:\\Users\\ACER\\gitClones\\ML_ProffCourse\\Day-12\\WordPrediction.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r4Y03CP3eFc",
        "outputId": "92b9ef24-418c-4451-97fd-518249a5984e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "2VY8gI3W3k3o"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'stars influence'\n",
        "def prediction(text):\n",
        "  for i in range(5):\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "    pos = np.argmax(model.predict(padded_token_text))\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == pos:\n",
        "        text = text + \" \" + word\n",
        "        print(text)\n",
        "        time.sleep(2)"
      ],
      "metadata": {
        "id": "V5MFFiMI3pFY"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('kasto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDgG82Br5kke",
        "outputId": "7b6ac673-86d8-4691-a124-e63039d842d0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "kasto bhai\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "kasto bhai ra\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "kasto bhai ra xa\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "kasto bhai ra xa pada\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "kasto bhai ra xa pada pada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lO-TNgir6DES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}