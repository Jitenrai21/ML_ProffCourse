{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6254655-ecd6-4c37-8284-481ffc7b46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "docs = ['Hello world',\n",
    "\t\t'Nepal Nepal',\n",
    "\t\t'hip hip hurray',\n",
    "\t\t'great to see you',\n",
    "\t\t'k xa khaber',\n",
    "\t\t'kohli kohli',\n",
    "\t\t'got it',\n",
    "\t\t'hello hello',\n",
    "\t\t'okay talk you later'\n",
    "\t  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc8e3af-7887-4072-889b-c67ea5c358b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d14cde0-daef-44fa-b537-6cfecf0a9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Tokenizer object with a special token for out-of-vocabulary (OOV) words.\n",
    "# The 'oov_token' parameter ensures that any word not seen during the training phase\n",
    "# is replaced with the specified token ('Inez') in the tokenized output.\n",
    "tokenizer = Tokenizer(oov_token='Inez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8684f0-cbaf-4850-9b96-7cd0314abc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a27889-e4ca-4688-9498-f35da74fb7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Inez': 1,\n",
       " 'hello': 2,\n",
       " 'nepal': 3,\n",
       " 'hip': 4,\n",
       " 'you': 5,\n",
       " 'kohli': 6,\n",
       " 'world': 7,\n",
       " 'hurray': 8,\n",
       " 'great': 9,\n",
       " 'to': 10,\n",
       " 'see': 11,\n",
       " 'k': 12,\n",
       " 'xa': 13,\n",
       " 'khaber': 14,\n",
       " 'got': 15,\n",
       " 'it': 16,\n",
       " 'okay': 17,\n",
       " 'talk': 18,\n",
       " 'later': 19}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the word index dictionary created by the Tokenizer.\n",
    "# The 'word_index' attribute contains a mapping of words to their respective integer indices.\n",
    "# This mapping is generated after the Tokenizer is fit on a text corpus.\n",
    "# Example: {'word1': 1, 'word2': 2, ...}\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee1019a-e182-4aa1-8a39-afb65d746feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hello', 3),\n",
       "             ('world', 1),\n",
       "             ('nepal', 2),\n",
       "             ('hip', 2),\n",
       "             ('hurray', 1),\n",
       "             ('great', 1),\n",
       "             ('to', 1),\n",
       "             ('see', 1),\n",
       "             ('you', 2),\n",
       "             ('k', 1),\n",
       "             ('xa', 1),\n",
       "             ('khaber', 1),\n",
       "             ('kohli', 2),\n",
       "             ('got', 1),\n",
       "             ('it', 1),\n",
       "             ('okay', 1),\n",
       "             ('talk', 1),\n",
       "             ('later', 1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the frequency of words\n",
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17a2ddb-cb13-4f1d-89de-0e400f2b3678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of  input words\n",
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833f25af-9b46-4d97-a282-b679f89e8cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 7],\n",
       " [3, 3],\n",
       " [4, 4, 8],\n",
       " [9, 10, 11, 5],\n",
       " [12, 13, 14],\n",
       " [6, 6],\n",
       " [15, 16],\n",
       " [2, 2],\n",
       " [17, 18, 5, 19]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting a list of text documents ('docs') into sequences of integers using the Tokenizer.\n",
    "# The 'texts_to_sequences' method replaces each word in the documents with its corresponding\n",
    "# integer index from the Tokenizer's word index.\n",
    "# Words not found in the word index (out-of-vocabulary words) will be replaced with the OOV token's index.\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "# Displaying the resulting sequences of integers.\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7134bff1-9ceb-4ba6-8f20-7dc3d9e8e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962bcc10-2208-4e89-84c9-c7e8113040d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  7,  0,  0],\n",
       "       [ 3,  3,  0,  0],\n",
       "       [ 4,  4,  8,  0],\n",
       "       [ 9, 10, 11,  5],\n",
       "       [12, 13, 14,  0],\n",
       "       [ 6,  6,  0,  0],\n",
       "       [15, 16,  0,  0],\n",
       "       [ 2,  2,  0,  0],\n",
       "       [17, 18,  5, 19]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, padding='post')\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418c0f5-b07e-41f0-8202-f12ccef1d6af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
